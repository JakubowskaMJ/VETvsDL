{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as spio\n",
    "import glob\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2DTranspose, Concatenate, ConvLSTM2D, Activation, Dense, Dropout, Convolution2D, MaxPooling2D, AveragePooling2D, Flatten, BatchNormalization\n",
    "from matplotlib import image, pyplot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go5_v_9aoJpe"
   },
   "outputs": [],
   "source": [
    "a=1138\n",
    "h=1838\n",
    "\n",
    "folder='.../f_c01/*.jpg'\n",
    "filenames = glob.glob(folder) \n",
    "filenames.sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXMH13UkLRE1"
   },
   "outputs": [],
   "source": [
    "train_val_img, test_img = train_test_split(filenames, test_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmcVNibiLkEc"
   },
   "outputs": [],
   "source": [
    "train_img, val_img = train_test_split(train_val_img, test_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h10xJQ892GK"
   },
   "outputs": [],
   "source": [
    "im_samples = 128\n",
    "im_size = 32\n",
    "im_rep = 25\n",
    "def read_images(fnames):\n",
    "  for f in fnames:\n",
    "    im = image.imread(f)\n",
    "    conc = int(f.split('\\\\')[-1][1:3])\n",
    "    for _ in range(im_samples):\n",
    "      ix = np.random.randint(low=a, high=h-im_size)\n",
    "      iy = np.random.randint(low=a, high=h-im_size)\n",
    "      yield (np.array(im[iy:iy+im_size, ix:ix+im_size, :]) / 128.)-1., np.array([conc]) # np.array([conc / 50.])\n",
    "\n",
    "def samples_count(fnames):\n",
    "  return len(fnames) * im_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5SNEmzrcgs7",
    "outputId": "59e687f5-b9a1-475f-803b-b3c7dbe03335"
   },
   "outputs": [],
   "source": [
    "samples_count(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RE0OonxHcmnU",
    "outputId": "9d365470-9a7a-4610-e79a-49c4668dfabb"
   },
   "outputs": [],
   "source": [
    "samples_count(val_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZgQgSFycnIV",
    "outputId": "30c0c11e-dda4-4dcd-c1ab-ec1a6fc4ee87"
   },
   "outputs": [],
   "source": [
    "samples_count(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RELkBb5CK2X"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: read_images(train_img),\n",
    "    output_signature=(tf.TensorSpec((im_size, im_size, 3), dtype=\"float32\"), tf.TensorSpec((1), dtype=\"float32\"))\n",
    ")\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: read_images(val_img),\n",
    "    output_signature=(tf.TensorSpec((im_size, im_size, 3), dtype=\"float32\"), tf.TensorSpec((1), dtype=\"float32\"))\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: read_images(test_img),\n",
    "    output_signature=(tf.TensorSpec((im_size, im_size, 3), dtype=\"float32\"), tf.TensorSpec((1), dtype=\"float32\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtnJJ6BF8lmP"
   },
   "source": [
    "# Main Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(y_true, y_pred):\n",
    "  y_true = y_true\n",
    "  y_pred = y_pred\n",
    "  return keras.losses.mean_absolute_error(y_true, y_pred) + keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def loss_class(y_true, y_pred):\n",
    "  y_true_idx = tf.cast(y_true, tf.int64)\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(y_true_idx, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input(shape=(im_size, im_size, 3))  \n",
    "\n",
    "x = keras.layers.Conv2D(48, (9, 9), padding=\"valid\")(inp)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation(activation='relu')(x)\n",
    "x = keras.layers.AveragePooling2D(pool_size=(9, 9), strides=(1,1), padding='valid')(x)\n",
    "x = keras.layers.Dropout(0.1)(x) \n",
    "\n",
    "x = keras.layers.Conv2D(96, (9, 9), padding=\"valid\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation(activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "x = keras.layers.ConvLSTM1D(48, kernel_size=7, return_sequences=True)(x)\n",
    "x = keras.layers.Conv2D(48, (2, 2), activation=\"relu\", padding=\"valid\")(x)\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(150, activation='relu')(x)\n",
    "x = keras.layers.Dense(50, activation='relu')(x)\n",
    "x = keras.layers.Dense(1, activation = 'linear')(x)\n",
    "\n",
    "model3 = keras.Model(inp, x)\n",
    "model3.compile(loss=new_loss, optimizer=keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.7, beta_2=0.9, decay=0.00005), metrics=[]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCsdxpiTFT09"
   },
   "outputs": [],
   "source": [
    "bsize = 160\n",
    "train_batches = train_dataset.repeat().shuffle(samples_count(train_img)).batch(bsize).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_batches = val_dataset.repeat().shuffle(samples_count(val_img)).batch(bsize).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_sr0t6xoaaF",
    "outputId": "6f6ca056-e07d-4ec4-d6ce-3a7a3edb6014"
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "save_best = keras.callbacks.ModelCheckpoint(\n",
    "    'best',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")\n",
    "lr_drop = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    factor=0.1,\n",
    ")\n",
    "\n",
    "history = model3.fit(\n",
    "    train_batches, \n",
    "    validation_data=val_batches, \n",
    "    steps_per_epoch=samples_count(train_img) // bsize,\n",
    "    validation_steps=samples_count(val_img) // bsize,\n",
    "    epochs=5,\n",
    "    callbacks=[lr_drop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylim(0, 10)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['val_loss', 'loss'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "print('TRAIN SET');\n",
    "XX = []\n",
    "YY = []\n",
    "for xx, yy in train_dataset:\n",
    "    XX.append(xx)\n",
    "    YY.append(yy)\n",
    "XX = np.array(XX)\n",
    "YY = np.array(YY)\n",
    "\n",
    "\n",
    "pred_val = model3.predict(XX)\n",
    "\n",
    "s1 = 128\n",
    "s2 = 195\n",
    "YY1 = np.reshape(YY, (s1, s2, 1), order='F')\n",
    "YY2 = np.mean(YY1, axis=0)\n",
    "\n",
    "pred_val1 = np.reshape(pred_val, (s1, s2), order='F')\n",
    "pred_val2 = np.mean(pred_val1, axis=0)\n",
    "\n",
    "print('RMSEC:', np.sqrt(mean_squared_error(YY2[:, 0], pred_val2)))\n",
    "\n",
    "corr,_ = pearsonr(YY2[:,0],pred_val2)\n",
    "print('R^2 test:', corr**2)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(YY2[:, 0], pred_val2[:])\n",
    "ax.plot([YY2.min(), YY2.max()], [YY2.min(), YY2.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUc3dMklDfox",
    "outputId": "b1f868d7-0eac-43c3-bf33-330de597dcd3"
   },
   "outputs": [],
   "source": [
    "print('VALIDATION SET');\n",
    "XX = []\n",
    "YY = []\n",
    "for xx, yy in val_dataset:\n",
    "    XX.append(xx)\n",
    "    YY.append(yy)\n",
    "XX = np.array(XX)\n",
    "YY = np.array(YY)\n",
    "\n",
    "pred_val = model3.predict(XX)\n",
    "\n",
    "s1 = 128\n",
    "s2 = 30\n",
    "YY1 = np.reshape(YY, (s1, s2, 1), order='F')\n",
    "YY2 = np.mean(YY1, axis=0)\n",
    "\n",
    "pred_val1 = np.reshape(pred_val, (s1, s2), order='F')\n",
    "pred_val2 = np.mean(pred_val1, axis=0)\n",
    "\n",
    "print('RMSECV:', np.sqrt(mean_squared_error(YY2[:, 0], pred_val2)))\n",
    "corr,_ = pearsonr(YY2[:,0],pred_val2)\n",
    "print('R^2 test:', corr**2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(YY2[:, 0], pred_val2[:])\n",
    "ax.plot([YY2.min(), YY2.max()], [YY2.min(), YY2.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "U8VYypqJEP-N",
    "outputId": "86e43bee-b08a-49c1-f7b2-46ece31e6cde"
   },
   "outputs": [],
   "source": [
    "print('TEST SET');\n",
    "XXt = []\n",
    "YYt = []\n",
    "for xx, yy in test_dataset:\n",
    "    XXt.append(xx)\n",
    "    YYt.append(yy)\n",
    "XXt = np.array(XXt)\n",
    "YYt = np.array(YYt)\n",
    "\n",
    "pred_test= model3.predict(XXt)\n",
    "\n",
    "s1 = 128\n",
    "s3 = 50\n",
    "YYt1 = np.reshape(YYt, (s1, s3, 1), order='F')\n",
    "YYt2 = np.mean(YYt1, axis=0)\n",
    "\n",
    "pred_test1 = np.reshape(pred_test, (s1, s3), order='F')\n",
    "pred_test2 = np.mean(pred_test1, axis=0)\n",
    "\n",
    "print('RMSEP:', np.sqrt(mean_squared_error(YYt2[:, 0], pred_test2)))\n",
    "corr,_ = pearsonr(YYt2[:,0],pred_test2)\n",
    "print('R^2 test:', corr**2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(YYt2[:, 0], pred_test2)\n",
    "ax.plot([YYt2.min(), YYt2.max()], [YYt2.min(), YYt2.max()], 'k--', lw=1)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Miod01_fc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
